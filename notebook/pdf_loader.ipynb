{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09c8222",
   "metadata": {},
   "source": [
    "### RAG Pipeline - Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b4ce3",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cf0127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee295545",
   "metadata": {},
   "source": [
    "### Read PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0d41ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: Cover_Letter_Fatma_Fendri.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: DAX Calculation.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e08a131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content=\"Fatma Fendri\\nCurd-Jürgens-Str. 14\\n81739 München\\n■ fendrifatma2@gmail.com | ■ +49 151 58333426\\nCHECK24 Vergleichsportal Mietwagen GmbH\\nAugsburg\\nMünchen, den 25. September 2025\\nApplication for (Junior) Data Scientist (m/w/d) – Fokus auf LLMs und GenAI\\nDear Hiring Team,\\nI am excited to apply for the position of (Junior) Data Scientist – Fokus auf Large Language\\nModels (LLMs) und GenAI at CHECK24. With a strong academic background in software\\nengineering and practical experience in Machine Learning, NLP, and LLMs, I am eager to\\ncontribute my expertise to further enhance your Mietwagenvergleich product.\\nDuring my end-of-study internship at Neofacto Luxembourg, I worked extensively on the\\nAira (AI Review Assistant) project, where I implemented and evaluated NLP and LLM models,\\ncontributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with\\nLangChain, PyTorch, TensorBoard, and dataset management for fine-tuning. In addition, I\\nam skilled in Python, Git/GitLab, and API development, and I have worked in agile Scrum\\nteams using Jira, all of which align well with the requirements at CHECK24.\\nBeyond technical expertise, I am highly motivated by the opportunity to bring\\nstate-of-the-art AI methods into real-world applications that reach millions of users. The\\nchallenge of not only building advanced models but also integrating and monitoring them in\\nproduction systems excites me greatly. I see CHECK24's dynamic and collaborative\\nenvironment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\\nI am fluent in English, French, and Arabic, and I am currently learning German to further\\nstrengthen my communication skills in a professional context.\\nI would welcome the opportunity to discuss how my skills and motivation match your vision\\nat CHECK24. Thank you very much for considering my application.\\nKind regards,\\nFatma Fendri\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'DAX Calculation', 'source': '..\\\\data\\\\pdf\\\\DAX Calculation.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'DAX Calculation.pdf', 'file_type': 'pdf'}, page_content='DAX  Calculation    Total  Revenue  =  SUM(pizza_sales[total_price])  \\n   Total  Orders  =  DISTINCTCOUNT(pizza_sales[order_id])  \\n  Avg  Order  Value  =  [Total  Revenue]/[Total  Orders]  \\n  Total  Pizzas  sold  =  SUM(pizza_sales[quantity])  \\n  Avg  Pizzas  Per  Order  =  [Total  Pizzas  sold] /  [Total  Orders]')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb3a40",
   "metadata": {},
   "source": [
    "### Text splitting get into chunks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8861ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \" ,\"\"]\n",
    "    )\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"split  {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"content : {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a7977a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split  2 documents into 4 chunks\n",
      "\n",
      "Example chunk:\n",
      "content : Fatma Fendri\n",
      "Curd-Jürgens-Str. 14\n",
      "81739 München\n",
      "■ fendrifatma2@gmail.com | ■ +49 151 58333426\n",
      "CHECK24 Vergleichsportal Mietwagen GmbH\n",
      "Augsburg\n",
      "München, den 25. September 2025\n",
      "Application for (Junior) ...\n",
      "Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content='Fatma Fendri\\nCurd-Jürgens-Str. 14\\n81739 München\\n■ fendrifatma2@gmail.com | ■ +49 151 58333426\\nCHECK24 Vergleichsportal Mietwagen GmbH\\nAugsburg\\nMünchen, den 25. September 2025\\nApplication for (Junior) Data Scientist (m/w/d) – Fokus auf LLMs und GenAI\\nDear Hiring Team,\\nI am excited to apply for the position of (Junior) Data Scientist – Fokus auf Large Language\\nModels (LLMs) und GenAI at CHECK24. With a strong academic background in software\\nengineering and practical experience in Machine Learning, NLP, and LLMs, I am eager to\\ncontribute my expertise to further enhance your Mietwagenvergleich product.\\nDuring my end-of-study internship at Neofacto Luxembourg, I worked extensively on the\\nAira (AI Review Assistant) project, where I implemented and evaluated NLP and LLM models,\\ncontributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content=\"contributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with\\nLangChain, PyTorch, TensorBoard, and dataset management for fine-tuning. In addition, I\\nam skilled in Python, Git/GitLab, and API development, and I have worked in agile Scrum\\nteams using Jira, all of which align well with the requirements at CHECK24.\\nBeyond technical expertise, I am highly motivated by the opportunity to bring\\nstate-of-the-art AI methods into real-world applications that reach millions of users. The\\nchallenge of not only building advanced models but also integrating and monitoring them in\\nproduction systems excites me greatly. I see CHECK24's dynamic and collaborative\\nenvironment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content='environment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\\nI am fluent in English, French, and Arabic, and I am currently learning German to further\\nstrengthen my communication skills in a professional context.\\nI would welcome the opportunity to discuss how my skills and motivation match your vision\\nat CHECK24. Thank you very much for considering my application.\\nKind regards,\\nFatma Fendri'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'DAX Calculation', 'source': '..\\\\data\\\\pdf\\\\DAX Calculation.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'DAX Calculation.pdf', 'file_type': 'pdf'}, page_content='DAX  Calculation    Total  Revenue  =  SUM(pizza_sales[total_price])  \\n   Total  Orders  =  DISTINCTCOUNT(pizza_sales[order_id])  \\n  Avg  Order  Value  =  [Total  Revenue]/[Total  Orders]  \\n  Total  Pizzas  sold  =  SUM(pizza_sales[quantity])  \\n  Avg  Pizzas  Per  Order  =  [Total  Pizzas  sold] /  [Total  Orders]')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadd72e",
   "metadata": {},
   "source": [
    "### Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4da80724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e085b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    def __init__(self, model_name:str = \"all-miniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager \n",
    "        Args : \n",
    "            model_name : HuggingFace Model name for sentence embeddings \n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentenceTransformer model\"\"\"\n",
    "        try: \n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model Loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}:{e}\") \n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate Embeddings for a list of texts\n",
    "\n",
    "        Args: \n",
    "            texts: List of text strings to embed\n",
    "        \n",
    "        returns:\n",
    "            numpy array of embeddings with shape (len(texts),embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not Loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts ...\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "    \"\"\"def get_embedding_dimension(self) -> int:\n",
    "        Get the embedding dimension of the model\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        return self.model.get_sentence_embedding_dimension()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0676475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-miniLM-L6-v2\n",
      "Model Loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x264332a2a50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Initialize the embedding Manager \n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63152d9",
   "metadata": {},
   "source": [
    "### VectorStore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8aea7816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x264332a2ba0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if embeddings is None:\n",
    "            raise ValueError(\"Embeddings array is None. Check the generate_embeddings function.\")\n",
    "    \n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b74a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content='Fatma Fendri\\nCurd-Jürgens-Str. 14\\n81739 München\\n■ fendrifatma2@gmail.com | ■ +49 151 58333426\\nCHECK24 Vergleichsportal Mietwagen GmbH\\nAugsburg\\nMünchen, den 25. September 2025\\nApplication for (Junior) Data Scientist (m/w/d) – Fokus auf LLMs und GenAI\\nDear Hiring Team,\\nI am excited to apply for the position of (Junior) Data Scientist – Fokus auf Large Language\\nModels (LLMs) und GenAI at CHECK24. With a strong academic background in software\\nengineering and practical experience in Machine Learning, NLP, and LLMs, I am eager to\\ncontribute my expertise to further enhance your Mietwagenvergleich product.\\nDuring my end-of-study internship at Neofacto Luxembourg, I worked extensively on the\\nAira (AI Review Assistant) project, where I implemented and evaluated NLP and LLM models,\\ncontributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with'),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content=\"contributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with\\nLangChain, PyTorch, TensorBoard, and dataset management for fine-tuning. In addition, I\\nam skilled in Python, Git/GitLab, and API development, and I have worked in agile Scrum\\nteams using Jira, all of which align well with the requirements at CHECK24.\\nBeyond technical expertise, I am highly motivated by the opportunity to bring\\nstate-of-the-art AI methods into real-world applications that reach millions of users. The\\nchallenge of not only building advanced models but also integrating and monitoring them in\\nproduction systems excites me greatly. I see CHECK24's dynamic and collaborative\\nenvironment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\"),\n",
       " Document(metadata={'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-09-25T21:05:59+00:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-09-25T21:05:59+00:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\Cover_Letter_Fatma_Fendri.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Cover_Letter_Fatma_Fendri.pdf', 'file_type': 'pdf'}, page_content='environment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\\nI am fluent in English, French, and Arabic, and I am currently learning German to further\\nstrengthen my communication skills in a professional context.\\nI would welcome the opportunity to discuss how my skills and motivation match your vision\\nat CHECK24. Thank you very much for considering my application.\\nKind regards,\\nFatma Fendri'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'DAX Calculation', 'source': '..\\\\data\\\\pdf\\\\DAX Calculation.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'DAX Calculation.pdf', 'file_type': 'pdf'}, page_content='DAX  Calculation    Total  Revenue  =  SUM(pizza_sales[total_price])  \\n   Total  Orders  =  DISTINCTCOUNT(pizza_sales[order_id])  \\n  Avg  Order  Value  =  [Total  Revenue]/[Total  Orders]  \\n  Total  Pizzas  sold  =  SUM(pizza_sales[quantity])  \\n  Avg  Pizzas  Per  Order  =  [Total  Pizzas  sold] /  [Total  Orders]')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8904190c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fatma Fendri\\nCurd-Jürgens-Str. 14\\n81739 München\\n■ fendrifatma2@gmail.com | ■ +49 151 58333426\\nCHECK24 Vergleichsportal Mietwagen GmbH\\nAugsburg\\nMünchen, den 25. September 2025\\nApplication for (Junior) Data Scientist (m/w/d) – Fokus auf LLMs und GenAI\\nDear Hiring Team,\\nI am excited to apply for the position of (Junior) Data Scientist – Fokus auf Large Language\\nModels (LLMs) und GenAI at CHECK24. With a strong academic background in software\\nengineering and practical experience in Machine Learning, NLP, and LLMs, I am eager to\\ncontribute my expertise to further enhance your Mietwagenvergleich product.\\nDuring my end-of-study internship at Neofacto Luxembourg, I worked extensively on the\\nAira (AI Review Assistant) project, where I implemented and evaluated NLP and LLM models,\\ncontributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with',\n",
       " \"contributed to the transition from OpenAI/GPT to LLAMA, and applied techniques such as\\nembedding, summarization, and classification. I also gained hands-on experience with\\nLangChain, PyTorch, TensorBoard, and dataset management for fine-tuning. In addition, I\\nam skilled in Python, Git/GitLab, and API development, and I have worked in agile Scrum\\nteams using Jira, all of which align well with the requirements at CHECK24.\\nBeyond technical expertise, I am highly motivated by the opportunity to bring\\nstate-of-the-art AI methods into real-world applications that reach millions of users. The\\nchallenge of not only building advanced models but also integrating and monitoring them in\\nproduction systems excites me greatly. I see CHECK24's dynamic and collaborative\\nenvironment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\",\n",
       " 'environment as the perfect place to combine my analytical mindset, problem-solving\\nabilities, and enthusiasm for Generative AI with tangible customer impact.\\nI am fluent in English, French, and Arabic, and I am currently learning German to further\\nstrengthen my communication skills in a professional context.\\nI would welcome the opportunity to discuss how my skills and motivation match your vision\\nat CHECK24. Thank you very much for considering my application.\\nKind regards,\\nFatma Fendri',\n",
       " 'DAX  Calculation    Total  Revenue  =  SUM(pizza_sales[total_price])  \\n   Total  Orders  =  DISTINCTCOUNT(pizza_sales[order_id])  \\n  Avg  Order  Value  =  [Total  Revenue]/[Total  Orders]  \\n  Total  Pizzas  sold  =  SUM(pizza_sales[quantity])  \\n  Avg  Pizzas  Per  Order  =  [Total  Pizzas  sold] /  [Total  Orders]']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert text to embeddings \n",
    "texts = [doc.page_content for doc in chunks]\n",
    "texts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28250cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 4 texts ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (4, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-8.5021585e-02, -4.9779918e-02, -4.7065220e-03, ...,\n",
       "        -2.9942289e-02, -4.5879532e-02,  3.0200059e-02],\n",
       "       [-3.5634048e-02, -7.6290078e-02, -1.5442902e-02, ...,\n",
       "        -4.3754607e-02, -3.9055906e-02, -1.8587785e-02],\n",
       "       [ 1.3585211e-02, -6.1329506e-02,  2.9929355e-02, ...,\n",
       "         5.2718416e-02, -7.7405073e-02, -3.7696049e-02],\n",
       "       [ 4.2117448e-05,  7.7661268e-02,  1.0731682e-02, ...,\n",
       "         7.7019085e-04, -1.4245086e-02, -8.2083717e-02]],\n",
       "      shape=(4, 384), dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Generate the embeddings \n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc453d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 4 documents to vector store...\n",
      "Successfully added 4 documents to vector store\n",
      "Total documents in collection: 4\n"
     ]
    }
   ],
   "source": [
    "### Store in the vector DB \n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66216e5c",
   "metadata": {},
   "source": [
    "### Retriever Pipeline from VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7d38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869189b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
